{
  "Abdin et al. - 2024 - Phi-4 Technical Report.pdf": "Abdin2024Phi4",
  "Arcuri and Briand - 2014 - A Hitchhiker's guide to statistical tests for assessing randomized algorithms in software engineerin.pdf": "Arcuri2014Hitchhikers",
  "Barnett et al. - 2015 - Helping Developers Help Themselves Automatic Decomposition of Code Review Changesets.pdf": "Barnett2015Helping",
  "Belcak et al. - 2025 - Small Language Models are the Future of Agentic AI.pdf": "Belcak2025Small",
  "Chitty-Venkata et al. - 2025 - LLM-Inference-Bench Inference Benchmarking of Large Language Models on AI Accelerators.pdf": "Chitty-Venkata2025LLMInferenceBench",
  "Dias et al. - 2015 - Untangling fine-grained code changes.pdf": "Dias2015Untangling",
  "Fan et al. - 2023 - Large Language Models for Software Engineering Survey and Open Problems.pdf": "Fan2023Large",
  "Fan et al. - 2024 - Detect Hidden Dependency to Untangle Commits.pdf": "Fan2024Detect",
  "Fan et al. - 2024 - Exploring the Capabilities of LLMs for Code Change Related Tasks.pdf": "Fan2024Exploring",
  "Herzig and Zeller - 2011 - Untangling Changes.pdf": "Herzig2011Untangling",
  "Herzig and Zeller - 2013 - The impact of tangled code changes 1.pdf": "Herzig2013Impact",
  "Herzig and Zeller - 2013 - The impact of tangled code changes.pdf": null,
  "Herzig et al. - 2016 - The impact of tangled code changes on defect prediction models.pdf": "Herzig2016Impact",
  "Hou et al. - 2024 - Large Language Models for Software Engineering A Systematic Literature Review.pdf": "Hou2024Large",
  "Hu et al. - 2021 - LoRA Low-Rank Adaptation of Large Language Models.pdf": "Hu2021LoRA",
  "Kirinuki et al. - 2014 - Hey! are you committing tangled changes.pdf": "Kirinuki2014Hey",
  "Li et al. - 2022 - UTANGO untangling commits with context-aware, graph-based, code change clustering learning model.pdf": "Li2022UTANGO",
  "Li et al. - 2024 - Understanding Code Changes Practically with Small-Scale Language Models.pdf": "Li2024Understanding",
  "Lin et al. - 2023 - CCT5 A Code-Change-Oriented Pre-trained Model.pdf": "Lin2023CCT5",
  "Liu et al. - 2023 - An Empirical Study of Parameter-Efficient Fine-Tuning Methods for Pre-Trained Code Models.pdf": "Liu2023Empirical",
  "Lu et al. - 2025 - Small Language Models Survey, Measurements, and Insights.pdf": "Lu2025Small",
  "Muylaert and De Roover - 2018 - Untangling Composite Commits Using Program Slicing.pdf": "Muylaert2018Untangling",
  "Ranaldi and Freitas - 2024 - Aligning Large and Small Language Models via Chain-of-Thought Reasoning.pdf": "Ranaldi2024Aligning",
  "Shen et al. - 2021 - SmartCommit a graph-based interactive assistant for activity-oriented commits.pdf": "Shen2021SmartCommit",
  "Vaswani et al. - 2017 - Attention is All you Need.pdf": "Vaswani2017Attention",
  "Wu and Zhu - 2020 - Multi-label classification do Hamming loss and subset accuracy really conflict with each other.pdf": "Wu2020Multilabel",
  "Xu et al. - 2025 - Detecting and Untangling Composite Commits via Attributed Graph Modeling.pdf": "Xu2025Detecting",
  "Yang et al. - 2025 - Qwen3 Technical Report.pdf": "Yang2025Qwen3",
  "Zeng - 2025 - A First Look at Conventional Commits Classification.pdf": "Zeng2025First"
}
